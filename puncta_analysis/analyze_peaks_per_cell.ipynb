{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of puncta size and intensity in individual cell nuclei\n",
    "\n",
    "Detect and segment puncta and analyze their size and intensity. Calculate puncta statistics per cell nucleus.\n",
    "\n",
    "## Requirements\n",
    "- A folder with images that should be analyzed.  All z-layers for a specific sample must be combined into a single file. To combine z-layers and channels, run [images_to_stack.ipynb](images_to_stack.ipynb).\n",
    "- A folder with segmented cell nuclei. To segment cell nuclei, run [segment_cells.ipynb](segment_cells.ipynb).\n",
    "\n",
    "## Config\n",
    "\n",
    "### The following code imports and declares functions used for the processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "import intake_io\n",
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from skimage.measure import regionprops_table\n",
    "\n",
    "from am_utils.utils import walk_dir, imsave\n",
    "from am_utils.parallel import run_parallel\n",
    "from lib import mutual_information_2d, segment_puncta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & parameters\n",
    "\n",
    "### Data\n",
    "`input_dir`: folder with images to be analyzed\n",
    "\n",
    "`segm_dir`: folder with segmented cell nuclei\n",
    "\n",
    "`output_dir`: folder to save results\n",
    "\n",
    "### Channel parameters\n",
    "\n",
    "`channel_names`: list of channel names, e.g `['GFP', 'DNA']`\n",
    "\n",
    "`puncta_channels`: list of channels to use for puncta segmentation (e.g. `[\"GFP\"]`)\n",
    "\n",
    "\n",
    "### Puncta detection parameters\n",
    "\n",
    "`minsize_um`: minimal sigma for the Laplacian of Gaussian detection (microns); default is 0.2\n",
    "\n",
    "`maxsize_um`: maximal sigma for the Laplacian of Gaussian detection (microns); default is 2\n",
    "\n",
    "`num_sigma`: number of sigma values for the Laplacian of Gaussian detection; default is 5\n",
    "\n",
    "`overlap`: a value between 0 and 1; if two blobs overlaps by a fraction greater than this value, the smaller blob is eliminated; default is 1 (blobs are removed only if overlapping completely)\n",
    "\n",
    "`threshold_detection`: threshold for detecting LoG blobs. The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect blobs with less intensities\n",
    "\n",
    "`threshold_segmentation`: Threshold for puncta segmentation. The way the threshold is applied is determined by `segmentation_mode`. For mode 0, choose values in the order of 0.001; for mode 1, choose values in the order of 50; for mode 2, choose values in the order of 3. Reduce to detect more/larger puncta, increase to detect fewer/smaller puncta\n",
    "\n",
    "`threshold_detection` and `threshold_segmentation` for mode 0 should be close to 0, and can be both positive and negative\n",
    "\n",
    "`threshold_background`: threshold used to post-filter puncta in cells with diffuse signal. This threshold is provided relative to the median GFP intensity inside cells (e.g, `threshold_background` = 2 will result in all puncta with intensity lower than two median GPF (background) intensities being removed). Set to 0 to keep all puncta.\n",
    "\n",
    "`segmentation_mode`: determines the mode how `threshold_segmentation` is applied; 0: apply absolute threshold in LoG space; 1: apply threshold relative to background in LoG space; 2: apply threshold relative to the background in image intensity space.\n",
    "\n",
    "### Other parameters\n",
    "\n",
    "`max_threads`: number of processes to run in parallel; default is 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data paths and analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_dir = \"/research/sharedresources/cbi/common/Anna/test/input\"\n",
    "segm_dir = \"/research/sharedresources/cbi/common/Anna/test/Analysis/cell_segmentation\"\n",
    "output_dir = \"/research/sharedresources/cbi/common/Anna/test/Analysis\"\n",
    "\n",
    "cell_stats_dir = 'quantification_cells'\n",
    "puncta_stats_dir = 'quantification_puncta'\n",
    "puncta_segm_dir = 'puncta_segmentation_with_raw'\n",
    "\n",
    "channel_names = [\"DNA\", \"GFP\"]\n",
    "puncta_channels = [\"GFP\"]\n",
    "\n",
    "minsize_um = 0.2  # minimal sigma for the Laplacian of Gaussian detection (microns)\n",
    "maxsize_um = 2  # maximal sigma for the Laplacian of Gaussian detection (microns)\n",
    "num_sigma = 5  # number of sigma values for the Laplacian of Gaussian detection\n",
    "\n",
    "overlap = 1  # A value between 0 and 1. If two blobs overlaps by a fraction greater than this value, the smaller blob is eliminated.\n",
    "threshold_detection = 0.001 # The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect blobs with less intensities\n",
    "threshold_segmentation = 50  # Threshold for puncta segmentation in the LoG scale space. Reduce to detect more/larger puncta, increase to detect fewer/smaller puncta\n",
    "\n",
    "threshold_background = 3\n",
    "\n",
    "max_threads = 20    # number of processes to run in parallel\n",
    "segmentation_mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code lists all datasets in the input directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "samples = walk_dir(input_dir)\n",
    "\n",
    "print(f'{len(samples)} images were found:')\n",
    "print(np.array(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code segments and quantifies puncta in all input images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "def quantify(item, input_dir, output_dir, segm_dir=None, \n",
    "             channel_names=None, puncta_channels=None, output_dir_puncta=None, output_dir_puncta_segm=None,\n",
    "             threshold_detection=None, threshold_segmentation=None, **puncta_kwargs):\n",
    "    sample = item\n",
    "    dataset = intake_io.imload(sample, metadata={\"coords\": {'c': channel_names}})\n",
    "    sample_name = sample[len(input_dir):].replace(sample.split('.')[-1], '')\n",
    "        \n",
    "    scale = np.array([dataset['z'][1], dataset['y'][1], dataset['x'][1]])\n",
    "    channels = dataset['c'].data\n",
    "    \n",
    "    # load cell segmentation\n",
    "    cells = np.ones_like(np.array(dataset.loc[dict(c=channels[0])]['image'].data))    \n",
    "    if segm_dir is not None:\n",
    "        segm_fn = sample.replace(input_dir, segm_dir).replace(sample.split('.')[-1], 'tif')\n",
    "        if os.path.exists(segm_fn):\n",
    "            cells = io.imread(segm_fn)\n",
    "            \n",
    "    dist_to_border = ndimage.morphology.distance_transform_edt(cells > 0, sampling=scale)\n",
    "    \n",
    "          \n",
    "    # compute cell stats\n",
    "    cell_stats = pd.DataFrame(regionprops_table(label_image=cells,\n",
    "                                                properties=['label', 'area', 'centroid']))\n",
    "    cell_stats = cell_stats.rename(columns={'area': 'cell volume pix', \n",
    "                                            'centroid-0': 'z', \n",
    "                                            'centroid-1': 'y',\n",
    "                                            'centroid-2': 'x',\n",
    "                                            'label': 'cell label'})\n",
    "    cell_stats['cell volume um'] = cell_stats['cell volume pix']*np.prod(scale)\n",
    "    \n",
    "    for cind, channel in enumerate(channels):\n",
    "        channel_data = np.array(dataset.loc[dict(c=channel)]['image'].data)\n",
    "        intensity_stats = regionprops_table(label_image=cells,\n",
    "                                            intensity_image=channel_data,\n",
    "                                            properties=['label', 'mean_intensity'])\n",
    "        cell_stats[channel + ' mean intensity per nucleus'] = intensity_stats['mean_intensity']\n",
    "        cell_stats[channel + \n",
    "                   ' integrated intensity per nucleus'] = cell_stats[channel + \n",
    "                                                                     ' mean intensity per nucleus'] * cell_stats['cell volume pix']\n",
    "        cell_stats[channel + ' mean background intensity'] = np.mean(channel_data[np.where(cells == 0)])\n",
    "        cell_stats[channel + ' integrated background intensity'] = np.sum(channel_data[np.where(cells == 0)])\n",
    "        \n",
    "        other_channels = []\n",
    "        for other_channel in channels[cind+1:]:\n",
    "            other_channels.append((other_channel, np.array(dataset.loc[dict(c=other_channel)]['image'].data)))\n",
    "        \n",
    "        for i in range(len(cell_stats)):\n",
    "            cur_cell_pix = np.where(cells == cell_stats['cell label'].iloc[i])\n",
    "            cell_stats.at[i, channel + ' entropy'] = entropy(np.histogram(channel_data[cur_cell_pix], bins=channel_data.max())[0])\n",
    "            \n",
    "            for channel2, channel_data2 in other_channels:\n",
    "                cell_stats.at[i, 'Mutual information ' + channel + \n",
    "                              ' vs ' + channel2] = mutual_information_2d(channel_data[cur_cell_pix], channel_data2[cur_cell_pix],\n",
    "                                                                               bins=max([channel_data[cur_cell_pix].max(), \n",
    "                                                                                         channel_data2[cur_cell_pix].max()]))\n",
    "                cell_stats.at[i, 'Pearson correlation ' + channel + \n",
    "                              ' vs ' + channel2] = np.corrcoef(channel_data[cur_cell_pix]*1., channel_data2[cur_cell_pix]*1.)[0,1]\n",
    "        del other_channels\n",
    "      \n",
    "    cell_stats['condition'] = sample.split('/')[-2]\n",
    "    cell_stats['sample'] = sample.split('/')[-1]\n",
    "    \n",
    "    if output_dir_puncta_segm is not None:\n",
    "        output_stack = np.zeros((len(channel_names) + len(puncta_channels) + 1,) + cells.shape)\n",
    "        for ch_ind, chname in enumerate(channel_names):\n",
    "            output_stack[ch_ind] = np.array(dataset.loc[dict(c=chname)]['image'].data)\n",
    "        output_stack[-1] = cells\n",
    "    \n",
    "    # segment puncta\n",
    "    if puncta_channels is not None:\n",
    "        puncta_stats_all = pd.DataFrame()\n",
    "        threshold_detection = np.ravel(threshold_detection)\n",
    "        threshold_segmentation = np.ravel(threshold_segmentation)\n",
    "        if len(threshold_detection) == 1:\n",
    "            threshold_detection = np.ones(len(puncta_channels))*threshold_detection[0]\n",
    "        if len(threshold_segmentation) == 1:\n",
    "            threshold_segmentation = np.ones(len(puncta_channels))*threshold_segmentation[0]\n",
    "        for pc_ind, puncta_channel in enumerate(puncta_channels):\n",
    "            puncta_channel_data = np.array(dataset.loc[dict(c=puncta_channel)]['image'].data)\n",
    "            puncta = segment_puncta(puncta_channel_data, cells, scale,\n",
    "                                    threshold_detection=threshold_detection[pc_ind],\n",
    "                                    threshold_segmentation=threshold_segmentation[pc_ind],\n",
    "                                    **puncta_kwargs)\n",
    "       \n",
    "            # compute puncta stats\n",
    "            puncta_stats = pd.DataFrame(regionprops_table(label_image=puncta, \n",
    "                                                          intensity_image=dist_to_border,\n",
    "                                                          properties=['label', 'centroid', 'area', 'mean_intensity']\n",
    "                                                         ))\n",
    "            puncta_stats = puncta_stats.rename(columns={\n",
    "                                                        'mean_intensity': 'distance to nucleus border um',\n",
    "                                                        'centroid-0': 'z', \n",
    "                                                        'centroid-1': 'y',\n",
    "                                                        'centroid-2': 'x',\n",
    "                                                        'area': 'volume_pix'\n",
    "                                                       })\n",
    "            puncta_stats['volume_um'] = puncta_stats['volume_pix']*np.prod(scale)\n",
    "            puncta_stats['cell_label'] = cells[np.int_(np.round_(puncta_stats['z'])),\n",
    "                                               np.int_(np.round_(puncta_stats['y'])),\n",
    "                                               np.int_(np.round_(puncta_stats['x']))]\n",
    "            \n",
    "            # remove puncta outside cells (if any cells were detected)\n",
    "            if cells.max() > 0:\n",
    "                cell_label = np.array(puncta_stats['cell_label'])\n",
    "                ind = np.where(cell_label == 0)\n",
    "                bv = np.unique(np.array(puncta_stats['label'])[ind])\n",
    "                ix = np.in1d(puncta.ravel(), bv).reshape(puncta.shape)\n",
    "                puncta[ix] = 0 \n",
    "\n",
    "                ind = np.where(cell_label > 0)\n",
    "                puncta_stats = puncta_stats.iloc[ind].reset_index(drop=True)\n",
    "    \n",
    "            # remove large puncta\n",
    "            maxvol = 4./3*np.pi * (puncta_kwargs['maxsize_um']*3)**3\n",
    "            l_large = puncta_stats[puncta_stats['volume_um'] > maxvol]['label']\n",
    "            for l in l_large:\n",
    "                puncta[np.where(puncta == l)] = 0           \n",
    "            puncta_stats = puncta_stats[puncta_stats['volume_um'] <= maxvol].reset_index(drop=True)\n",
    "            \n",
    "            if output_dir_puncta_segm is not None:\n",
    "                output_stack[len(channel_names) + pc_ind] = puncta\n",
    "            \n",
    "            \n",
    "            # compute cell stats\n",
    "            for i in range(len(cell_stats)):\n",
    "                current_cell = puncta_stats[puncta_stats['cell_label'] == cell_stats['cell label'].iloc[i]]\n",
    "                cell_stats.at[i, rf'number of {puncta_channel} puncta'] = len(current_cell)\n",
    "                if len(current_cell) > 0:\n",
    "                    cell_stats.at[i, rf'total {puncta_channel} puncta volume per nucleus um'] = np.sum(current_cell['volume_um'])\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta volume per nucleus um'] = np.mean(current_cell['volume_um'])\n",
    "                    cell_stats.at[i, rf'total {puncta_channel} puncta volume per nucleus pix'] = np.sum(current_cell['volume_pix'])\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta volume per nucleus pix'] = np.mean(current_cell['volume_pix'])\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta distance to nucleus border um'] = np.mean(current_cell['distance to nucleus border um'])\n",
    "                else:\n",
    "                    cell_stats.at[i, rf'total {puncta_channel} puncta volume per nucleus um'] = 0\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta volume per nucleus um'] = 0\n",
    "                    cell_stats.at[i, rf'total {puncta_channel} puncta volume per nucleus pix'] = 0\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta volume per nucleus pix'] = 0\n",
    "                    cell_stats.at[i, rf'average {puncta_channel} puncta distance to nucleus border um'] = 0\n",
    "    \n",
    "    \n",
    "            for channel in channels:\n",
    "                channel_data = np.array(dataset.loc[dict(c=channel)]['image'].data)\n",
    "                \n",
    "                # intensity stats per puncta\n",
    "                intensity_stats = regionprops_table(label_image=puncta,\n",
    "                                                    intensity_image=channel_data,\n",
    "                                                    properties=['label', 'mean_intensity'])\n",
    "                \n",
    "                puncta_stats[channel + ' mean intensity per puncta'] = intensity_stats['mean_intensity']\n",
    "                puncta_stats[channel + \n",
    "                             ' integrated intensity per puncta'] = intensity_stats['mean_intensity'] * puncta_stats['volume_pix']\n",
    "                \n",
    "                # intensity stats per cells inside/outside puncta            \n",
    "                for label_img, location in zip([cells*(puncta > 0), cells*(puncta == 0)], \n",
    "                                               [rf'inside {puncta_channel} puncta', rf'outside {puncta_channel} puncta']):\n",
    "                \n",
    "                    intensity_stats = regionprops_table(label_image=label_img,\n",
    "                                                        intensity_image=channel_data,\n",
    "                                                        properties=['label', 'area', 'mean_intensity'])\n",
    "                    ind = cell_stats[cell_stats['cell label'].isin(intensity_stats['label'])].index\n",
    "\n",
    "                    cell_stats.at[ind, channel + ' mean intensity ' + location] = intensity_stats['mean_intensity']\n",
    "                    cell_stats.at[ind, channel + ' integrated intensity ' + \n",
    "                                  location] = np.int_(intensity_stats['mean_intensity'] * intensity_stats['area'])\n",
    "         \n",
    "        \n",
    "            puncta_stats['channel'] = puncta_channel\n",
    "            puncta_stats_all = pd.concat([puncta_stats_all, puncta_stats], ignore_index=True)\n",
    "     \n",
    "        puncta_stats_all['condition'] = sample.split('/')[-2]\n",
    "        puncta_stats_all['sample'] = sample.split('/')[-1]\n",
    "        \n",
    "        for key in puncta_kwargs.keys():\n",
    "            puncta_stats_all[key] = puncta_kwargs[key]\n",
    "        puncta_stats_all['threshold_detection'] = threshold_detection[0]\n",
    "        puncta_stats_all['threshold_segmentation'] = threshold_segmentation[0]\n",
    "        \n",
    "        if output_dir_puncta is not None:\n",
    "            os.makedirs(os.path.dirname(output_dir_puncta + sample_name + 'csv'), exist_ok=True)\n",
    "            puncta_stats_all.to_csv(output_dir_puncta + sample_name + 'csv', index=False)\n",
    "    \n",
    "    for key in puncta_kwargs.keys():\n",
    "        cell_stats[key] = puncta_kwargs[key]\n",
    "    cell_stats['threshold_detection'] = threshold_detection[0]\n",
    "    cell_stats['threshold_segmentation'] = threshold_segmentation[0]\n",
    "        \n",
    "    # save the cell stats\n",
    "    os.makedirs(os.path.dirname(output_dir + sample_name + 'csv'), exist_ok=True)\n",
    "    cell_stats.to_csv(output_dir + sample_name + 'csv', index=False)\n",
    "    \n",
    "    if output_dir_puncta_segm is not None:\n",
    "        \n",
    "        output_stack = xr.Dataset(data_vars=dict(image=(dataset['image'].dims, output_stack.astype(np.uint16))),\n",
    "                                  coords=dict(c=channel_names + \n",
    "                                              [cn + ' segmentation' for cn in puncta_channels] + \n",
    "                                              ['Nuclei segmentation'], \n",
    "                                              x=dataset.coords['x'], y=dataset.coords['y'], z=dataset.coords['z']),\n",
    "                                  attrs=dataset.attrs)\n",
    "        output_stack['image'].attrs = dataset['image'].attrs\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_dir_puncta_segm + sample_name + 'tif'), exist_ok=True)\n",
    "        intake_io.imsave(output_stack, output_dir_puncta_segm + sample_name + 'tif')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "# specify the analysis arguments\n",
    "kwargs = dict()\n",
    "kwargs['items'] = samples\n",
    "kwargs['input_dir'] = input_dir\n",
    "kwargs['segm_dir'] = segm_dir\n",
    "kwargs['output_dir'] = os.path.join(output_dir, cell_stats_dir)\n",
    "kwargs['output_dir_puncta'] = os.path.join(output_dir, puncta_stats_dir)\n",
    "kwargs['output_dir_puncta_segm'] = os.path.join(output_dir, puncta_segm_dir)\n",
    "\n",
    "kwargs['channel_names'] = channel_names\n",
    "kwargs['puncta_channels'] = puncta_channels\n",
    "kwargs['max_threads'] = max_threads\n",
    "kwargs['minsize_um'] = minsize_um\n",
    "kwargs['maxsize_um'] = maxsize_um\n",
    "kwargs['num_sigma'] = num_sigma\n",
    "kwargs['overlap'] = overlap\n",
    "kwargs['threshold_detection'] = threshold_detection\n",
    "kwargs['threshold_segmentation'] = threshold_segmentation\n",
    "kwargs['threshold_background'] = threshold_background\n",
    "kwargs['segmentation_mode'] = segmentation_mode\n",
    "\n",
    "# run the analysis in parallel\n",
    "run_parallel(process=quantify, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine stats\n",
    "for stats_dir in [cell_stats_dir, puncta_stats_dir]:\n",
    "    if os.path.exists(os.path.join(output_dir, stats_dir)):\n",
    "        stat = pd.DataFrame()\n",
    "        for fn in walk_dir(os.path.join(output_dir, stats_dir)):\n",
    "            stat = pd.concat([stat, pd.read_csv(fn)], ignore_index=False)\n",
    "        stat.to_csv(os.path.join(output_dir, stats_dir + '.csv'), index=False)\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code plots cell stats over conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "os.makedirs(output_dir + '/plots', exist_ok=True)\n",
    "stats = pd.read_csv(os.path.join(output_dir, cell_stats_dir + '.csv'))\n",
    "for col in stats.columns:\n",
    "    if not col in ['cell label', 'condition', 'sample']:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        ax = sns.boxplot(x = 'condition', y=col, data=stats) \n",
    "        plt.savefig(output_dir + '/plots/' + col.replace(' ', '_') + '.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nup98_puncta]",
   "language": "python",
   "name": "conda-env-nup98_puncta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
