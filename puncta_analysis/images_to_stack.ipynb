{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert individual z-layers and channels to stacks\n",
    "\n",
    "Individual images for z-layers and channels are combined to one stack per sample\n",
    "\n",
    "## Requirements\n",
    "- A folder with images that should be converted\n",
    "\n",
    "## Config\n",
    "\n",
    "### The following code imports and declares functions used for the processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import intake_io\n",
    "from tqdm import tqdm\n",
    "from am_utils.utils import walk_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data paths and analysis parameters\n",
    "\n",
    "### Please provide data paths:\n",
    "\n",
    "`input_dir`: folder with images of cells to be segmented\n",
    "\n",
    "`output_dir`: folder to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_dir = \"/research/sharedresources/cbi/data_exchange/kriwagrp/05282021_CoLocalization\"\n",
    "output_dir = \"/research/sharedresources/cbi/common/Anna/test/input\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code lists all image files in the input directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "samples = walk_dir(input_dir)\n",
    "\n",
    "print(f'{len(samples)} images were found:')\n",
    "print(np.array(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify codes for channel and z-position:\n",
    "\n",
    "Specify the sequence of characters that precedes the channel and z-position numbering, including the separator (e.g. \"_\") that precedes the channel code.\n",
    "\n",
    "For example, if the image name is \"my_experiment_position1_C0_z001.tif\", the codes should be as follows:\n",
    "\n",
    "`channel_code` = \"_C\"\n",
    "\n",
    "`z_position_code` = \"_z\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_code = \"_C\"\n",
    "z_position_code = \"_Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code sorts channels and z-positions into 3D stacks and extracts voxel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "sources = []\n",
    "tags = []\n",
    "# try different order of channel and z tags to extract the shorted i tag\n",
    "for code in [channel_code, z_position_code]:\n",
    "    tag = {}\n",
    "    if channel_code is not None:\n",
    "        tag['c'] = channel_code\n",
    "    if z_position_code is not None:\n",
    "        tag['z'] = z_position_code\n",
    "    if channel_code is not None and z_position_code is not None:\n",
    "        tag['i'] = re.compile(rf\"{input_dir}(.*){code}\\d+\")\n",
    "    tags.append(tag)\n",
    "    sources.append(intake_io.source.FilePatternSource(input_dir, \n",
    "                                                      axis_tags=tag,\n",
    "                                                      extensions=['.' + samples[0].split('.')[-1]], \n",
    "                                                      include_filters=[], \n",
    "                                                      exclude_filters=[],\n",
    "                                                      ))\n",
    "    \n",
    "# select the source corresponding to the shortest base string\n",
    "if 'i' in sources[0]._files.files.columns:\n",
    "    fns = np.array([src._files.files.iloc[0][\"i\"] for src in sources])\n",
    "\n",
    "    minind = np.where(fns == min(fns, key=len))[0][0]\n",
    "else:\n",
    "    minind = 0\n",
    "    \n",
    "src = sources[minind]\n",
    "tag = tags[minind]\n",
    "npartitions = intake_io.imload(src, metadata_only=True)['npartitions']\n",
    "\n",
    "print(fr'{npartitions} stacks found')\n",
    "\n",
    "# extract voxel size\n",
    "print('Extracting metadata...')\n",
    "coords = dict({'x': None, 'y': None, 'z': None})\n",
    "img = intake_io.imload(src, partition=0)\n",
    "for key in coords.keys():\n",
    "    if key in img.coords:\n",
    "        coords[key] = img.coords[key].data[1]\n",
    "            \n",
    "print('The following voxel sizes were detected:')\n",
    "for key in coords.keys():\n",
    "    print(rf'{key}: {coords[key]}')\n",
    "        \n",
    "print('\\n The following channels have been detected:')\n",
    "print(img['c'].data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify correct voxel size \n",
    "\n",
    "Keep `None`, if the value loaded from the dataset is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "y = None\n",
    "z = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify channels names\n",
    "\n",
    "If you'd like to relabel channels, specify channel names as an array (e.g. ['channel_1', 'channel_2']). Specify `None` to keep the default channel labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = ['DNA', 'GFP', 'mCherry']\n",
    "# channel_names = ['GFP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code relabels channels and reassigns voxel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "vs = [x, y, z]\n",
    "for i, c in enumerate(['x', 'y', 'z']):\n",
    "    if vs[i] is not None:\n",
    "        coords[c] = vs[i]\n",
    "\n",
    "src = intake_io.source.FilePatternSource(input_dir,\n",
    "                                        axis_tags=tag,\n",
    "                                        extensions=['.' + samples[0].split('.')[-1]],\n",
    "                                        metadata={\"spacing\": coords,\n",
    "                                                  \"coords\": {'c': channel_names}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code load a random image/stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "dataset = intake_io.imload(src, partition=np.random.randint(npartitions))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code saves the combined stacks into the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "fns = src._files.files['i'].unique()\n",
    "for i in tqdm(range(npartitions)):\n",
    "    dataset = intake_io.imload(src, coords=coords, partition=i)\n",
    "    fn = output_dir + fns[i].replace(' ', '_') + '.tif'\n",
    "    os.makedirs(os.path.dirname(fn), exist_ok=True)\n",
    "    intake_io.imsave(dataset, fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nup98_puncta]",
   "language": "python",
   "name": "conda-env-nup98_puncta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
