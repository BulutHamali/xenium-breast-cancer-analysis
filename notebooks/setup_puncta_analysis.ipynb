{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment and quantify puncta in individual cells (Setup)\n",
    "\n",
    "Detect and segment puncta and analyze their size and intensity. Calculate puncta statistics per cell nucleus.\n",
    "\n",
    "Run this notebook cell-by-cell and follow the instructions.\n",
    "\n",
    "## Requirements\n",
    "- A folder with images that should be analyzed.  All z-layers for a specific sample must be combined into a single file. To combine z-layers and channels, run [run_images_to_stack.ipynb](run_images_to_stack.ipynb). To compute puncta statistics per cell, cell segmentation should be provided as an additional channel. To segment cells/nuclei, run [run_cell_segmentation.ipynb](run_cell_segmentation.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Config\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### The following code imports and declares functions used for the processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import intake_io\n",
    "from skimage.feature import blob_log\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage\n",
    "import pylab as plt\n",
    "import holoviews as hv\n",
    "\n",
    "from am_utils.utils import walk_dir\n",
    "from punctatools.lib.segment import calculate_background_image, centers_to_markers, threshold_puncta\n",
    "from punctatools.lib.utils import show_image_and_nuclei, show_image_and_segmentation, display_blobs\n",
    "from punctatools.lib.utils import load_parameters, save_parameters, convert_params\n",
    "\n",
    "        \n",
    "hv.extension(\"bokeh\", \"matplotlib\") \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Set up the data to segment\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### Please provide data paths:\n",
    "\n",
    "#### Option 1 (preferred)\n",
    "\n",
    "`parameter_file`: parameter file (json) with previously set up parameters (e.g. with [setup_cell_segmentation.ipynb](setup_cell_segmentation.ipynb))\n",
    "\n",
    "`output_dir`: output directory for the puncta analysis results\n",
    "\n",
    "<hr style=\"height:0.5px;\">\n",
    "\n",
    "#### Option 2\n",
    "\n",
    "`input_dir`: folder with input images; if the cell/nuclei segmentation was done this should be the output of the cell/nuclei segmentation. To segment cells/nuclei, run [run_cell_segmentation.ipynb](run_cell_segmentation.ipynb).\n",
    "\n",
    "`cell_segmentation`: Set to `True` if the cell/nuclei segmentation was performed. Otherwise set to `False`. Default if `False`\n",
    "\n",
    "`output_dir`: output directory for the puncta analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "parameter_file = 'parameters.json'\n",
    "output_dir = \"../test_output/puncta_analysis\"\n",
    "\n",
    "# input_dir = \"../example_data/stacks\"\n",
    "# cell_segmentation = True\n",
    "# output_dir = \"../test_output/puncta_analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code lists all image files in the input directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "if 'parameter_file' in vars():\n",
    "    with open(parameter_file) as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    if 'cell_segmentation_dir' in params:\n",
    "        input_dir = params['cell_segmentation_dir']\n",
    "        cell_segmentation = True\n",
    "    else:\n",
    "        input_dir = params['converted_data_dir']\n",
    "        cell_segmentation = False\n",
    "        \n",
    "elif not ('input_dir' in vars() and 'cell_segmentation' in vars()):\n",
    "    raise ValueError('Values of either \"parameter_file\" or \"input_dir\" and'\\\n",
    "                     '\"cell_segmentation\" must be provided')\n",
    "\n",
    "    \n",
    "print(rf\"Input directory: {input_dir}\")\n",
    "if not cell_segmentation:\n",
    "    print('No cell segmentation provided')\n",
    "samples = walk_dir(input_dir)\n",
    "\n",
    "print(f'\\n{len(samples)} images were found:')\n",
    "for i in range(len(samples)):\n",
    "    print(i, samples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please provide the index of the sample to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code loads a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "sample = samples[sample_index]\n",
    "dataset = intake_io.imload(sample)\n",
    "print(dataset, '\\n')\n",
    "nchannels = len(dataset['c'].data)\n",
    "if cell_segmentation:\n",
    "    nchannels -= 1\n",
    "print(rf\"Number of channels: {nchannels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify the indices of puncta channels and the channel to set up\n",
    "\n",
    "The indices start from 0. \n",
    "\n",
    "`puncta_channels`: list of channel indices, starting form 0, where puncta should be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncta_channels = [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code displays the puncta channels and the nuclei segmentation of the current image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "if 'z' in dataset.dims:\n",
    "    print(rf'Current number of z layers: {len(dataset[\"z\"].data)}')\n",
    "else:\n",
    "    print('No z layers were found, the dataset is 2D')\n",
    "    \n",
    "if cell_segmentation:\n",
    "    nuclei = dataset.loc[dict(c=dataset['c'].data[-1])]['image'].data\n",
    "else:\n",
    "    nuclei = None\n",
    "    \n",
    "show_image_and_nuclei(dataset, puncta_channels, nuclei)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please select a small box to test the analysis:\n",
    "\n",
    "Keep the width and height 200 - 500 pixels.\n",
    "\n",
    "To used the entire image, set x, y, z, width, height and depth to `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0    # coordinate of the left border\n",
    "y = 70   # coordinate of the top border\n",
    "z = 0\n",
    "width = 200   # width of the box\n",
    "height = 200  # height of the box\n",
    "depth = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code crops the dataset and displays the cropped area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "sp = intake_io.get_spacing(dataset)[-1]\n",
    "\n",
    "ds_crop = dataset.copy()\n",
    "\n",
    "if x is not None and width is not None:\n",
    "    ds_crop = ds_crop.loc[dict(x=slice(x*sp, (x+width-1)*sp))]\n",
    "if y is not None and height is not None:\n",
    "    ds_crop = ds_crop.loc[dict(y=slice(y*sp, (y+height-1)*sp))]\n",
    "    \n",
    "if 'z' in dataset.dims and z is not None and depth is not None:\n",
    "    sp = intake_io.get_spacing(dataset)[0]\n",
    "    ds_crop = ds_crop.loc[dict(z=slice(z*sp, (z+depth-1)*sp))]\n",
    "    \n",
    "sp = intake_io.get_spacing(dataset)[-1]\n",
    "ds_crop.coords['x'] = np.arange(ds_crop['image'].shape[-1])*sp\n",
    "ds_crop.coords['y'] = np.arange(ds_crop['image'].shape[-2])*sp \n",
    "\n",
    "show_image_and_nuclei(ds_crop, puncta_channels, ds_crop.loc[dict(c=ds_crop['c'].data[-1])]['image'].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Set up puncta detection\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "The following are the steps to set up puncta detection. At each step, you will be asked to set up the corresponding parameters.\n",
    "\n",
    "1. Detect puncta centers\n",
    "2. Filter out centers based on their intensity relative to the background. \n",
    "3. Segment puncta masks from the background\n",
    "4. Remove large puncta and puncta outside cells/nuclei\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify parameters for detection of puncta centers\n",
    "\n",
    "You can specify one value or a list for each parameter. If one value is provided, the same value will be used for all channels. Provide a list if different values should be used for different puncta channels. The length of the list should be equal to the number of puncta channels.\n",
    "\n",
    "#### Frequent:\n",
    "\n",
    "`minsize_um`: minimal sigma for the Laplacian of Gaussian detection (microns); default is 0.2\n",
    "\n",
    "`maxsize_um`: maximal sigma for the Laplacian of Gaussian detection (microns); default is 2\n",
    "\n",
    "`threshold_detection`: threshold for detecting LoG blobs. The absolute lower bound for scale space maxima. Local maxima smaller than thresh are ignored. Reduce this to detect blobs with less intensities. Should be close to 0 and can be both positive and negative.\n",
    "\n",
    "#### Advanced:\n",
    "\n",
    "`num_sigma`: number of sigma values for the Laplacian of Gaussian detection; default is 5\n",
    "\n",
    "`overlap`: a value between 0 and 1; if two blobs overlaps by a fraction greater than this value, the smaller blob is eliminated; default is 1 (blobs are removed only if overlapping completely)\n",
    "\n",
    "<hr style=\"height:0.5px;\">\n",
    "\n",
    "If you are having trouble detecting puncta, start with very low value of `threshold_detection` (e.g. 0), and adjust `minsize_um` and `maxsize_um` to make sure that all puncta of relevant size are detected. After that, increase the value of `threshold_detection` to remove dim puncta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent:\n",
    "minsize_um = 0.2  \n",
    "maxsize_um = 2  \n",
    "threshold_detection = [0.001, 0.0001] \n",
    "\n",
    "# advanced:\n",
    "num_sigma = 5\n",
    "overlap = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the display option\n",
    "\n",
    "By default, the plots are displayed with holoviews, and you can zoom and pan. If this doesn't work, and the plots are not displayed, set the `holoviews` variable to `False` and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holoviews = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code detects puncta centers and shows results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "spacing = np.array(intake_io.get_spacing(dataset))\n",
    "chnames = ds_crop['c'].data\n",
    "imgs = []\n",
    "\n",
    "logblobs_all = []\n",
    "for i in range(len(puncta_channels)):\n",
    "    current_channel = puncta_channels[i]\n",
    "    minsize_um2, maxsize_um2, threshold_detection2, num_sigma2, overlap2 = convert_params(len(puncta_channels), \n",
    "                                                                                          i,\n",
    "                                                                                          minsize_um, maxsize_um, \n",
    "                                                                                          threshold_detection, \n",
    "                                                                                          num_sigma, overlap)\n",
    "    img = ds_crop.loc[dict(c=chnames[current_channel])]['image'].data\n",
    "    imgs.append(img)\n",
    "\n",
    "    # find blob centers with scale-adapted LoG\n",
    "    logblobs = blob_log(img,\n",
    "                        min_sigma=minsize_um2 / spacing,\n",
    "                        max_sigma=maxsize_um2 / spacing,\n",
    "                        num_sigma=int(num_sigma2),\n",
    "                        overlap=overlap2,\n",
    "                        threshold=threshold_detection2)\n",
    "    logblobs_all.append(logblobs)\n",
    "\n",
    "display_blobs(ds_crop, puncta_channels, [logblobs[:, :int(logblobs.shape[1]/2)] for logblobs in logblobs_all], holoviews=holoviews, wh=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Please specify parameters for background filtering\n",
    "\n",
    "You can specify one value or a list for each parameter. If one value is provided, the same value will be used for all channels. Provide a list if different values should be used for different puncta channels. The length of the list should be equal to the number of puncta channels.\n",
    "\n",
    "#### Frequent:\n",
    "\n",
    "`threshold_background`: threshold used to post-filter puncta in cells with diffuse signal. This threshold is provided relative to the median GFP intensity inside cells (e.g, `threshold_background` = 2 will result in all puncta with intensity lower than two median GPF (background) intensities being removed). Set to 0 to keep all puncta.\n",
    "\n",
    "`global_background`: If True, the background value is calculated globally as the `global_background_percentile` of all cells.(Default is True)\n",
    "\n",
    "\n",
    "#### Advanced:\n",
    "\n",
    "`background_percentile`: Percentile (between 0 and 100) of image intensity inside cell to calculate the background value. (Default is 50 (median)).\n",
    "\n",
    "`global_background_percentile`: Percentile (between 0 and 100) of cell background values to calculate the global background value. (Default is 95).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frequent:\n",
    "threshold_background = 3\n",
    "global_background = False\n",
    "\n",
    "# advanced:\n",
    "background_percentile = 50\n",
    "global_background_percentile = 95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The following code filters puncta centers based on their intensity relative to the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "\n",
    "cells = ds_crop.loc[dict(c=chnames[-1])]['image'].data\n",
    "bg_imgs = []\n",
    "new_centers = []\n",
    "markers_all = []\n",
    "\n",
    "for i in range(len(puncta_channels)):\n",
    "    current_channel = puncta_channels[i]\n",
    "    \n",
    "    threshold_background2, global_background2, \\\n",
    "    background_percentile2, global_background_percentile2 = convert_params(len(puncta_channels), i,\n",
    "                                                                          threshold_background, \n",
    "                                                                          global_background, \n",
    "                                                                          background_percentile, \n",
    "                                                                          global_background_percentile)\n",
    "\n",
    "    # calculate background image\n",
    "    bg_img = calculate_background_image(imgs[i], cells, global_background2,\n",
    "                                        global_background_percentile2, background_percentile2)\n",
    "    bg_imgs.append(bg_img)\n",
    "\n",
    "    # convert the blob centers to watershed markers, filter by background\n",
    "    markers = centers_to_markers(logblobs_all[i], imgs[i], bg_img, threshold_background2)\n",
    "    markers_all.append(markers)\n",
    "\n",
    "    # find blob centers with scale-adapted LoG\n",
    "    new_centers.append(np.array(ndimage.center_of_mass(markers, markers, np.unique(markers)[1:])))\n",
    "\n",
    "display_blobs(ds_crop, puncta_channels, new_centers, holoviews=holoviews, wh=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Please specify parameters for puncta segmentation \n",
    "\n",
    "You can specify one value or a list for each parameter. If one value is provided, the same value will be used for all channels. Provide a list if different values should be used for different puncta channels. The length of the list should be equal to the number of puncta channels.\n",
    "\n",
    "`threshold_segmentation`: Threshold for puncta segmentation. The way the threshold is applied is determined by `segmentation_mode`. For mode 0, choose values in the order of 0.001; for mode 1, choose values in the order of 50; for mode 2, choose values in the order of 3. Reduce to detect more/larger puncta, increase to detect fewer/smaller puncta\n",
    "\n",
    "`segmentation_mode`: 0, 1, or 2. Determines the mode how `threshold_segmentation` is applied; 0: apply absolute threshold in LoG space; 1: apply threshold relative to background in LoG space; 2: apply threshold relative to the background in image intensity space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_segmentation = 50\n",
    "segmentation_mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code segments pucnta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "puncta_prelim = []\n",
    "masks = []\n",
    "\n",
    "for i in range(len(puncta_channels)):\n",
    "    current_channel = puncta_channels[i]\n",
    "    threshold_segmentation2, segmentation_mode2 = convert_params(len(puncta_channels), i,\n",
    "                                                                 threshold_segmentation, segmentation_mode)\n",
    "\n",
    "    mask = threshold_puncta(imgs[i], bg_imgs[i], cells, minsize_um2, maxsize_um2, num_sigma2, spacing,\n",
    "                                segmentation_mode2, threshold_segmentation2)\n",
    "    masks.append(mask)\n",
    "    dist = ndimage.distance_transform_edt(mask, sampling=tuple(spacing))\n",
    "    puncta_prelim.append(watershed(-dist, markers_all[i], mask=mask))\n",
    "\n",
    "show_image_and_segmentation(ds_crop, puncta_channels, \n",
    "                            puncta_prelim, holoviews=holoviews, wh=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify parameters for puncta postprocessing \n",
    "\n",
    "`remove_out_of_cell`: If True, remove all puncta (parts) that are not inside cells/nuclei.\n",
    "\n",
    "`maxrad_um`: If not None, remove puncta with a radius larger than this value. Set to None to keep all detected puncta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_out_of_cell = False\n",
    "maxrad_um = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code removes large puncta and puncta (parts) that are out of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "puncta_all = []\n",
    "\n",
    "for i in range(len(puncta_channels)):\n",
    "    current_channel = puncta_channels[i]\n",
    "    \n",
    "    remove_out_of_cell2, maxrad_um2  = convert_params(len(puncta_channels), i,\n",
    "                                                      remove_out_of_cell, maxrad_um)\n",
    "    puncta = masks[i].copy()\n",
    "    \n",
    "    if remove_out_of_cell2 and cells is not None:\n",
    "        puncta = puncta * (cells > 0)\n",
    "\n",
    "\n",
    "    dist = ndimage.distance_transform_edt(puncta, sampling=tuple(spacing))\n",
    "    puncta = watershed(-dist, markers_all[i], mask=puncta)\n",
    "    if maxrad_um is not None:\n",
    "        llist = np.unique(puncta)\n",
    "        vol = ndimage.sum(puncta > 0, puncta, llist) * np.prod(spacing)\n",
    "        maxvol = 4. / 3 * np.pi * maxrad_um2 ** 3\n",
    "        ix = np.in1d(puncta.ravel(), llist[vol > maxvol]).reshape(puncta.shape)\n",
    "        puncta[ix] = 0\n",
    "    puncta_all.append(puncta)\n",
    "\n",
    "show_image_and_segmentation(ds_crop, puncta_channels, \n",
    "                            puncta_all, holoviews=holoviews, wh=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Run the full processing\n",
    "\n",
    "The parameters set up in this notebook will be used to segment images in batch.\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### The following code checks if the parameter file name was provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "if 'parameter_file' in vars():\n",
    "    print(rf\"The current parameter file name is '{parameter_file}'; \"\\\n",
    "          \"you can leave the 'parameter_file' variable commented\")\n",
    "else:\n",
    "    print(\"No parameter file was provided; please provide the parameter file name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_file = 'parameters.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify the number of processes to run in parallel\n",
    "\n",
    "\n",
    "`n_jobs`: number of processes to run in parallel. Set according to your workstation resources. Decrease if it runs out of memory. (Default is 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specify the list of channel names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = ['ch0', 'ch1', 'ch3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code checks the validity of the list of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "nchannels = len(dataset['c'].data)\n",
    "if cell_segmentation:\n",
    "    nchannels -= 1\n",
    "\n",
    "if len(channel_names) == nchannels:\n",
    "    print(\"The list of channel names is valid\")\n",
    "else:\n",
    "    print(rf\"The dataset contains {nchannels} channel, but {len(channel_names)} names were provided. \"\\\n",
    "          rf\"Please provide {nchannels} names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code saves the parameters\n",
    "\n",
    "To run the full processing, run the notebook [run_puncta_analysis.ipynb](run_puncta_analysis.ipynb) with the parameter values identified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#  Don't modify the code below  #\n",
    "#################################\n",
    "\n",
    "params = dict(\n",
    "    puncta_analysis_dir=os.path.realpath(output_dir),\n",
    "    puncta_segm_dir='puncta',\n",
    "    puncta_stat_dir='puncta_stats',\n",
    "    cell_stat_dir='cell_stats',\n",
    "    puncta_channels=puncta_channels,\n",
    "    cell_segmentation=cell_segmentation,\n",
    "    minsize_um=minsize_um,\n",
    "    maxsize_um=maxsize_um,\n",
    "    num_sigma=num_sigma,\n",
    "    overlap=overlap,\n",
    "    threshold_detection=threshold_detection,\n",
    "    threshold_background=threshold_background,\n",
    "    global_background=global_background,\n",
    "    global_background_percentile=global_background_percentile,\n",
    "    background_percentile=background_percentile,\n",
    "    threshold_segmentation=threshold_segmentation,\n",
    "    segmentation_mode=segmentation_mode,\n",
    "    remove_out_of_cell=remove_out_of_cell,\n",
    "    maxrad_um=maxrad_um,\n",
    "    n_jobs=n_jobs,\n",
    "    channel_names=channel_names\n",
    ")\n",
    "\n",
    "params = save_parameters(params, parameter_file)\n",
    "    \n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:punctatools]",
   "language": "python",
   "name": "conda-env-punctatools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
